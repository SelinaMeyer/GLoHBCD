{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e1292ad",
   "metadata": {},
   "source": [
    "### This is the code used to match the crawled forum data to Behavior Change Annotations\n",
    "Matching was last successfully tested in December, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fccb6a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec652f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnehmen = pd.read_json(path_or_buf=\"./Crawler/abnehmenOhneOp.json\")\n",
    "psycho = pd.read_json(path_or_buf=\"./Crawler/psychoTherapie.json\")\n",
    "anno_ids = pd.read_csv(\"annotations_all_ids.csv\", sep=';').sort_values([\"Annotation_post_id\", \"Annotation_Satz-ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e726b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnehmen[\"forum_name\"] = \"Abnehmen ohne OP\"\n",
    "psycho[\"forum_name\"] = \"Psychologsiche Therapie\"\n",
    "\n",
    "fora = pd.concat([psycho, abnehmen]).sort_values(\"post_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08674fd",
   "metadata": {},
   "source": [
    "we check that crawled forums and annotations have the same number of posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e49207b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated number of posts:  1202\n",
      "Crawled number of posts:  1202\n"
     ]
    }
   ],
   "source": [
    "print(\"Annotated number of posts: \", anno_ids[\"Annotation_post_id\"].nunique())\n",
    "print(\"Crawled number of posts: \", len(fora))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64beca20",
   "metadata": {},
   "source": [
    "It seems we are missing a post in the crawled data. It could have been removed since original data collection. We remove this post from the annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1d5be34",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_ids = anno_ids[anno_ids[\"Annotation_post_id\"].isin(fora[\"post_id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c8c0378",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_ids = pd.read_csv(\"annotions_crawled.csv\")\n",
    "fora.to_csv(\"fora.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e043ebd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>thread_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>content</th>\n",
       "      <th>forum_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wie lange zum Psychologen bis es das Attest gi...</td>\n",
       "      <td>16899</td>\n",
       "      <td>181007</td>\n",
       "      <td>26. März 2006, 21:09</td>\n",
       "      <td>Eisy</td>\n",
       "      <td>\\n\\nWie lange muß man sich Psychologisch behan...</td>\n",
       "      <td>Psychologsiche Therapie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auf was muß das Attest beim Psychlogen Ausgest...</td>\n",
       "      <td>17085</td>\n",
       "      <td>185772</td>\n",
       "      <td>4. April 2006, 15:52</td>\n",
       "      <td>Eisy</td>\n",
       "      <td>\\n\\nSo Termin steht habe mich entschieden wenn...</td>\n",
       "      <td>Psychologsiche Therapie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*klick*</td>\n",
       "      <td>17305</td>\n",
       "      <td>186269</td>\n",
       "      <td>5. April 2006, 12:32</td>\n",
       "      <td>rebecca76</td>\n",
       "      <td>\\n\\nhallöchen zusammen:499: :499:\\n\\nso, man l...</td>\n",
       "      <td>Psychologsiche Therapie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*klick*</td>\n",
       "      <td>17305</td>\n",
       "      <td>186322</td>\n",
       "      <td>5. April 2006, 13:36</td>\n",
       "      <td>rebecca76</td>\n",
       "      <td>\\n\\n@michael....mist...hier ises nun auch fast...</td>\n",
       "      <td>Psychologsiche Therapie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*klick*</td>\n",
       "      <td>17305</td>\n",
       "      <td>186330</td>\n",
       "      <td>5. April 2006, 13:44</td>\n",
       "      <td>Gabriella</td>\n",
       "      <td>\\n\\nHallo Rebecca ,,\\n\\nich mache seit ungefäh...</td>\n",
       "      <td>Psychologsiche Therapie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  thread_id  post_id  \\\n",
       "0  wie lange zum Psychologen bis es das Attest gi...      16899   181007   \n",
       "1  auf was muß das Attest beim Psychlogen Ausgest...      17085   185772   \n",
       "2                                            *klick*      17305   186269   \n",
       "3                                            *klick*      17305   186322   \n",
       "4                                            *klick*      17305   186330   \n",
       "\n",
       "                   date   username  \\\n",
       "0  26. März 2006, 21:09       Eisy   \n",
       "1  4. April 2006, 15:52       Eisy   \n",
       "2  5. April 2006, 12:32  rebecca76   \n",
       "3  5. April 2006, 13:36  rebecca76   \n",
       "4  5. April 2006, 13:44  Gabriella   \n",
       "\n",
       "                                             content               forum_name  \n",
       "0  \\n\\nWie lange muß man sich Psychologisch behan...  Psychologsiche Therapie  \n",
       "1  \\n\\nSo Termin steht habe mich entschieden wenn...  Psychologsiche Therapie  \n",
       "2  \\n\\nhallöchen zusammen:499: :499:\\n\\nso, man l...  Psychologsiche Therapie  \n",
       "3  \\n\\n@michael....mist...hier ises nun auch fast...  Psychologsiche Therapie  \n",
       "4  \\n\\nHallo Rebecca ,,\\n\\nich mache seit ungefäh...  Psychologsiche Therapie  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"fora.csv\").sort_values(\"post_id\")\n",
    "data.drop(columns={\"Unnamed: 0\"}, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81abfe4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16221"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delimiter = \"REPLACE\"   \n",
    " \n",
    "def break_line(match):\n",
    "   return match.group() + delimiter\n",
    "\n",
    "dict_of_regex_replacements = {r\"z\\. *b\\.\": \"zb\",  r\"z\\. *B\\.\": \"zb\",r\"EW\\.\": \"EW\",r\"Z\\. *B\\.\": \"zb\", r\"zB\\.\": \"zb\",\n",
    "                       r\"z\\.B\\.\": \"zb\", r\"zb\\.\": \"zb\",r\"z\\.B\": \"zb\", r\"z\\.b\": \"zb\", r\"u\\. *a\\.\": \"ua\", r\"etc\\.\": \"etc\", r\"etc\\.\\)\": \"etc\",\n",
    "                       r\" eig\\.\": \"eig\", r\"l\\.g\\.\": \"lg\", r\"o\\.k\\.\": \"ok\", r\"ca\\.\": \"ca\", r\"Ca\\.\": \"ca\", r\"d\\.m\\.\": \"dm\", r\"d\\.M\\.\": \"dm\",\n",
    "                       r\"p\\. *s\\.\": \"ps\", r\"P\\. *s\\.\": \"ps\", r\"P\\. *S\\.\": \"ps\", r\"z\\.t\\.\": \"zt\", r\"wg\\.\": \"wg\",r\"\\.-\": \"-\",\n",
    "                       r\"-\\.\": \"-\", r\"Tg\\.\": \"Tg\", r\"o\\. *ä\\.\": \"oä\", r\"d\\. *h\\.\": \"dh\", r\"D\\. *H\\.\": \"dh\", r\"d\\. *H\\.\": \"dh\",\n",
    "                       r\"dH\\.\": \"dh\",r\"dh\\.\": \"dh\", r\"z\\. *Zt\\.\": \"zzt\", r\"Dr\\.\": \"Dr\", r\"v\\. *a\\.\": \"va\", r\"\\d\\d\\.*\\d\\d\\.\": \"xx/xx/\",\n",
    "                       r\"s\\. *u\\.\": \"su\", r\"u\\.s\\.w\\.\": \"usw\", r\"usw\\.\":\"usw\",r\"soz\\.\": \"soz\", r\"vllt\\.\": \"vlt\", r\"\\(\\!\\)\": \" \",\n",
    "                       r\"ank\\.tzt\": \"ankotzt\", r\"\\!\\\" z\\.B\\.\": \"\\\" zb\",r\"Gr\\.\": \"Gr\", r\"Dez\\.\": \"Dez\", r\"(\\d+\\.)(\\d+\\.)\\d*\": \"xx/xx/xxxx\",\n",
    "                       r\"(\\d+\\.)(\\d+) \": \"12,3 \",r\"(\\d+\\.)(\\d+)\": \"xx/xx\", r\"\\d+\\.\\d+\\.\": \"xx/xx\", r\"bz\\.w\": \"bzw\", r\"Bzw\\.\": \"bzw\", \n",
    "                       r\"bzw\\.\": \"bzw\", r\"inkl\\.\": \"inkl\", r\"psych\\.\": \"psych\",r\"mind\\.\": \"mind\", r\"Min\\.\": \"Min\", r\" min\\.\": \"min\", r\"Verh\\.\": \"Verh\",\n",
    "                       r\"Ern\\.\": \"Ern\", r\"bezgl\\.\": \"bezgl\", r\"ltd\\.\": \"ltd\", r\"bspw\\.\": \"bspw\", r\"ltr\\.\": \"ltr\", r\"anschl\\.\": \"anschl\",\n",
    "                       r\"s\\.oliver\": \"soliver\", r\" event\\.\": \" event\", r\"std\\.\": \"std\", r\"Std\\.\": \"std\", r\"max\\.\": \"max\", r\"L\\.G\\.\": \"lg\",\n",
    "                       r\"LG\\.\": \"lg\", r\"tägl\\.\": \"tägl\", r\" u\\.\": \" u\", r\" u\\.\":\" u\", r\" od\\.\": \" od\",r\"Co\\.\": \"Co\", r\"co\\.\": \" co\",r\"bzgl\\.\": \"bzgl\", r\"evtl\\.\": \"evtl\",\n",
    "                       r\"pos\\.\": \"evtl\", r\"M\\.O\\.B\\.I\\.L\\.I\\.S\": \"mobilis\",r\"m\\.o\\.b\\.i\\.l\\.i\\.s\\.\": \"mobilis\", \"fddb\\.info\":\"fddb_info\", r\"i\\.d\\.R\\.*\": \"idR\",\n",
    "                       r\"z\\. *T\\.\":\"zT\", r\"Vit\\.\":\"Vit\",r\"ggf\\.\":\"ggf\", r\"m\\.E\\.\": \"mE\", r\"k\\.o\": \"ko\", r\"bezw\\.\":\"bzw\",r\"Dh\\.\":\"dh\", r\"Nr\\.\":\"Nr\", r\"Evtl\\.\":\"evtl\",\n",
    "                       r\"O\\.k\\.\":\"ok\", r\"D\\.h\\.\":\"dh\", r\"zBsp\\.\":\"zb\", r\"U\\.a\\.\":\"Ua\", r\"Bzgl\\.\":\"bzgl\", \"gr\\.\":\"gr\", \"d\\.h\":\"dh\", \"i\\.d\\.R\\.\":\"idR\"}\n",
    "\n",
    "dict_of_non_regex_replacements = {\"etc.\": \"etc\", \" u.\": \" u\", \"z.b.\": \"zb\", \" ca.\": \" ca\", \"Co.\": \"Co\", \"ggf.\":\"ggf\",\"ua.\":\"ua\", \"U.a.\":\"ua\",\n",
    "                               \"Bzgl.\": \"bzgl\", \"Mrs.\":\"Mrs\", \"Nr.\":\"Nr\", \"z.T.\":\"zT\", \"gr.\": \"gr\", \"(!)\": \"()\", \"d.h\": \"dh\", \"D.h.\":\"dh\",\n",
    "                               \"Vit.\":\"Vit\", \"m.E.\": \"mE\", \"k.o\": \"ko\", \"bezw.\":\"bzw\", \"O.k.\":\"ok\", \"Dh.\":\"dh\", \"Evtl.\":\"evtl\", \"Bsp.\":\"Bsp\", \"Bzgl.\":\"bzgl\", \"d.h\":\"dh\"}\n",
    "\n",
    "\n",
    "data[\"split\"] = \"\"\n",
    "\n",
    "for key in dict_of_regex_replacements.keys():\n",
    "    data[\"content\"].replace(key, dict_of_regex_replacements[key], inplace=True, regex=True)\n",
    "    \n",
    "for key in dict_of_non_regex_replacements.keys():\n",
    "    data[\"content\"].replace(key, dict_of_non_regex_replacements[key], inplace=True)\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    data.loc[index, \"split\"] = re.sub(r\"!+|\\?+|\\.+|\\!\\?+|\\?\\!+|\\.+\\?+\", break_line, data.loc[index,\"content\"])\n",
    "\n",
    "data = data.replace(r'\\n',' ', regex=True) \n",
    "data.drop(columns=\"content\", inplace=True)\n",
    "data = data.assign(split=data['split'].str.split(delimiter)).explode('split', ignore_index=True)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "234f82a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>thread_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>forum_name</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wie lange zum Psychologen bis es das Attest gi...</td>\n",
       "      <td>16899</td>\n",
       "      <td>181007</td>\n",
       "      <td>26. März 2006, 21:09</td>\n",
       "      <td>Eisy</td>\n",
       "      <td>Psychologsiche Therapie</td>\n",
       "      <td>Wie lange muß man sich Psychologisch behande...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wie lange zum Psychologen bis es das Attest gi...</td>\n",
       "      <td>16899</td>\n",
       "      <td>181007</td>\n",
       "      <td>26. März 2006, 21:09</td>\n",
       "      <td>Eisy</td>\n",
       "      <td>Psychologsiche Therapie</td>\n",
       "      <td>da ich noch nicht lange in Kiel bin wäre schö...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>auf was muß das Attest beim Psychlogen Ausgest...</td>\n",
       "      <td>17085</td>\n",
       "      <td>185772</td>\n",
       "      <td>4. April 2006, 15:52</td>\n",
       "      <td>Eisy</td>\n",
       "      <td>Psychologsiche Therapie</td>\n",
       "      <td>So Termin steht habe mich entschieden wenn e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*klick*</td>\n",
       "      <td>17305</td>\n",
       "      <td>186269</td>\n",
       "      <td>5. April 2006, 12:32</td>\n",
       "      <td>rebecca76</td>\n",
       "      <td>Psychologsiche Therapie</td>\n",
       "      <td>hallöchen zusammen:499: :499:  so, man liest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*klick*</td>\n",
       "      <td>17305</td>\n",
       "      <td>186269</td>\n",
       "      <td>5. April 2006, 12:32</td>\n",
       "      <td>rebecca76</td>\n",
       "      <td>Psychologsiche Therapie</td>\n",
       "      <td>aber was brauchts dazu dass es *klick* macht???</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  thread_id  post_id  \\\n",
       "0  wie lange zum Psychologen bis es das Attest gi...      16899   181007   \n",
       "1  wie lange zum Psychologen bis es das Attest gi...      16899   181007   \n",
       "2  auf was muß das Attest beim Psychlogen Ausgest...      17085   185772   \n",
       "3                                            *klick*      17305   186269   \n",
       "4                                            *klick*      17305   186269   \n",
       "\n",
       "                   date   username               forum_name  \\\n",
       "0  26. März 2006, 21:09       Eisy  Psychologsiche Therapie   \n",
       "1  26. März 2006, 21:09       Eisy  Psychologsiche Therapie   \n",
       "2  4. April 2006, 15:52       Eisy  Psychologsiche Therapie   \n",
       "3  5. April 2006, 12:32  rebecca76  Psychologsiche Therapie   \n",
       "4  5. April 2006, 12:32  rebecca76  Psychologsiche Therapie   \n",
       "\n",
       "                                               split  \n",
       "0    Wie lange muß man sich Psychologisch behande...  \n",
       "1   da ich noch nicht lange in Kiel bin wäre schö...  \n",
       "2    So Termin steht habe mich entschieden wenn e...  \n",
       "3    hallöchen zusammen:499: :499:  so, man liest...  \n",
       "4    aber was brauchts dazu dass es *klick* macht???  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d55ba333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both datasets have a length of 15533\n"
     ]
    }
   ],
   "source": [
    "nan_value = float(\"NaN\")\n",
    "\n",
    "list_to_replace = [\"\", \" \", \"  \", \"    \", \"   \", \"           \", \"      \", \"!\", \"?\", \".\", \"!!\", \"??\", \"..\",\n",
    "                  \"!!!\", \"???\", \"...\", \" !\", \" ?\", \" .\", \" !!\", \" ??\", \" ..\", \" !!!\", \" ???\", \"????\", \"  ...\", \"  ....\",\n",
    "                  \" ....\", \"....\", \".......\", \" ......\", \"    \", \".......\", \" ......\", \"  ....\", \"      \", \" ...\", \"                   \",\n",
    "                  \" .....\", \".....\", \"    ...\", \"     ...\", \"  .\", \"   .\", \"  ????\", \"     \", \"        \"]\n",
    "                   \n",
    "for item in list_to_replace:\n",
    "    data[\"split\"].replace(item, nan_value, inplace=True) \n",
    "\n",
    "data.dropna(subset = [\"split\"], inplace=True)\n",
    "data.reset_index(inplace=True)\n",
    "\n",
    "# Making sure that both datasets have the same length\n",
    "if (len(data) == len(anno_ids)):\n",
    "    print(\"Both datasets have a length of\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da9ac58",
   "metadata": {},
   "source": [
    "Aside: If they do not have the same length, posts might have been modified since the last testing of this code. In this case, it would be best to just drop those posts, that do not have the same length (i.e. compare value counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a508d36f",
   "metadata": {},
   "source": [
    "### We can now look at the posts, that have a single label and polarization\n",
    "\n",
    "These were used for the testing Inter-Rater reliability and conducting machine learning experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f886c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = anno_ids[[\"Annotation_thread_id\", \"Annotation_post_id\",\"Annotation_Satz-ID\",\"Label\", \"Sublabel\", \"Polarization\"]]\n",
    "forum_splitted = pd.concat([data,annotations], axis=1)\n",
    "forum_splitted.to_csv(\"forum_splitted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "468f8959",
   "metadata": {},
   "outputs": [],
   "source": [
    "forum_splitted = pd.read_csv(\"forum_splitted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad2013",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"C\", \"TS\", \"R\"]\n",
    "polarization = [\"+\", \"-\"]\n",
    "\n",
    "forum_splitted = forum_splitted[forum_splitted[\"Label\"].isin(categories)]\n",
    "forum_splitted = forum_splitted[forum_splitted[\"Polarization\"].isin(polarization)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b9fc76c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "forum_splitted.to_csv(\"Annotation_crawled_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1fd14c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ebfc1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forum_splitted = pd.read_csv(\"Annotation_crawled_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9198bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forum_splitted[\"Polarization\"].replace(\"+\", 1, inplace=True)\n",
    "forum_splitted[\"Polarization\"].replace(\"-\", 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7e215781",
   "metadata": {},
   "outputs": [],
   "source": [
    "forum_splitted[\"Label\"].replace(\"R\", 0, inplace=True)\n",
    "forum_splitted[\"Label\"].replace(\"TS\", 1, inplace=True)\n",
    "forum_splitted[\"Label\"].replace(\"C\", 2, inplace=True)\n",
    "\n",
    "forum_splitted[\"Sublabel\"].fillna(0, inplace=True)\n",
    "forum_splitted[\"Sublabel\"].replace(\"a\", 1, inplace=True)\n",
    "forum_splitted[\"Sublabel\"].replace(\"d\", 2, inplace=True)\n",
    "forum_splitted[\"Sublabel\"].replace(\"n\", 3, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6121142b",
   "metadata": {},
   "source": [
    "### Stratified Train-test split\n",
    "The training set will be used for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4b5eedc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = forum_splitted[[\"split\", \"Polarization\"]].copy()\n",
    "binary.rename(columns={\"split\":\"Sentence\", \"Polarization\":\"labels\"}, inplace=True)\n",
    "labels = forum_splitted[[\"split\", \"Label\"]].copy()\n",
    "labels.rename(columns={\"split\":\"Sentence\", \"Label\":\"labels\"}, inplace=True)\n",
    "\n",
    "# Sublabels are only applicable to sentences with label R. We subset the dataset accordingly.\n",
    "sublabels = forum_splitted[forum_splitted[\"Label\"] == 0]\n",
    "sublabels = sublabels[[\"split\", \"Sublabel\"]].copy()\n",
    "sublabels.rename(columns={\"split\":\"Sentence\", \"Sublabel\":\"labels\"}, inplace=True)\n",
    "binary_train, binary_test = train_test_split(binary,test_size=0.2, random_state=42, stratify=binary[\"labels\"])\n",
    "label_train, label_test = train_test_split(labels,test_size=0.2, random_state=42, stratify=labels[\"labels\"])\n",
    "sublabel_train, sublabel_test = train_test_split(sublabels,test_size=0.2, random_state=42, stratify=sublabels[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "11d956b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sublabel_train.to_csv(\"sublabel_train.csv\")\\nsublabel_test.to_csv(\"sublabel_test.csv\")'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_sustain = binary_train[binary_train[\"labels\"] == 0]\n",
    "binary_change = binary_train[binary_train[\"labels\"] == 1]\n",
    "binary_change_undersampled = binary_change.sample(binary_sustain.shape[0])\n",
    "binary_train_balanced = pd.concat([binary_sustain, binary_change_undersampled])\n",
    "binary_train_balanced = binary_train_balanced.sample(frac=1)\n",
    "\n",
    "binary_train_balanced.to_csv(\"valence_train_balanced.csv\")\n",
    "binary_test.to_csv(\"valence_test.csv\")\n",
    "\n",
    "label_R = label_train[label_train[\"labels\"] == 0]\n",
    "label_TS = label_train[label_train[\"labels\"] == 1]\n",
    "label_C = label_train[label_train[\"labels\"] == 2]\n",
    "label_R_undersampled = label_R.sample(label_TS.shape[0])\n",
    "label_train_balanced = pd.concat([label_R_undersampled, label_TS, label_C])\n",
    "label_train_balanced = label_train_balanced.sample(frac=1)\n",
    "\n",
    "label_train.to_csv(\"label_train_balanced.csv\")\n",
    "label_test.to_csv(\"label_test.csv\")\n",
    "\n",
    "\n",
    "sublabel_R = sublabel_train[sublabel_train[\"labels\"] == 0]\n",
    "sublabel_Ra = sublabel_train[sublabel_train[\"labels\"] == 1]\n",
    "sublabel_Rd = sublabel_train[sublabel_train[\"labels\"] == 2]\n",
    "sublabel_Rn = sublabel_train[sublabel_train[\"labels\"] == 3]\n",
    "sublabel_R_undersampled = sublabel_R.sample(sublabels_Ra.shape[0])\n",
    "sublabel_train_balanced = pd.concat([sublabel_R_downsampled, sublabel_Ra, sublabel_Rn, sublabel_Rd])\n",
    "sublabel_train_balanced = sublabel_train_balanced.sample(frac=1)\n",
    "sublabel_train.to_csv(\"sublabel_train_balanced.csv\")\n",
    "sublabel_test.to_csv(\"sublabel_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c112af7a",
   "metadata": {},
   "source": [
    "### same process for split by User activity level\n",
    "\n",
    "The 65 most active users produced 80% of the data. We want to test whether machine learning results are biased by user-specific language. So we produce training and test sets that allow us to train on the most active users and predict for the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65be0f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_active = list(counts[\"username\"][:65])\n",
    "train = forum_splitted[forum_splitted[\"username\"].isin(most_active)]\n",
    "test = forum_splitted[~forum_splitted[\"username\"].isin(most_active)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a409064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_train = train[[\"split\", \"Valence\"]].copy()\n",
    "binary_train.rename(columns={\"split\":\"Sentence\", \"Valence\":\"labels\"}, inplace=True)\n",
    "\n",
    "binary_sustain = binary_train[binary_train[\"labels\"] == 0]\n",
    "binary_change = binary_train[binary_train[\"labels\"] == 1]\n",
    "binary_change_downsampled = binary_change.sample(binary_sustain.shape[0])\n",
    "binary_train_balanced = pd.concat([binary_sustain, binary_change_downsampled])\n",
    "binary_train_balanced = binary_train_balanced.sample(frac=1)\n",
    "\n",
    "binary_test = test[[\"split\", \"Valence\"]].copy()\n",
    "binary_test.rename(columns={\"split\":\"Sentence\", \"Valence\":\"labels\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2666658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = train[[\"split\", \"Label\"]].copy()\n",
    "label_train.rename(columns={\"split\":\"Sentence\", \"Label\":\"labels\"}, inplace=True)\n",
    "\n",
    "label_R = label_train[label_train[\"labels\"] == 0]\n",
    "label_TS = label_train[label_train[\"labels\"] == 1]\n",
    "label_C = label_train[label_train[\"labels\"] == 2]\n",
    "label_R_downsampled = label_R.sample(label_TS.shape[0])\n",
    "label_train_balanced = pd.concat([label_R_downsampled, label_TS, label_C])\n",
    "label_train_balanced = label_train_balanced.sample(frac=1)\n",
    "\n",
    "label_test = test[[\"split\", \"Label\"]].copy()\n",
    "label_test.rename(columns={\"split\":\"Sentence\", \"Label\":\"labels\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa9fe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, we only use sentences with label R for our sublabel training and test set\n",
    "sublabels_R = train[train[\"Label\"] == 0]\n",
    "sublabels_train = sublabels_R[[\"split\", \"Sublabel\"]].copy()\n",
    "sublabels_train.rename(columns={\"split\":\"Sentence\", \"Sublabel\":\"labels\"}, inplace=True)\n",
    "\n",
    "sublabels_R = sublabels_train[sublabels_train[\"labels\"] == 0]\n",
    "sublabels_Ra = sublabels_train[sublabels_train[\"labels\"] == 1]\n",
    "sublabels_Rd = sublabels_train[sublabels_train[\"labels\"] == 2]\n",
    "sublabels_Rn = sublabels_train[sublabels_train[\"labels\"] == 3]\n",
    "sublabels_R_undersampled = sublabels_R.sample(sublabels_Ra.shape[0])\n",
    "sublabels_train_balanced = pd.concat([sublabels_R_undersampled, sublabels_Ra, sublabels_Rn, sublabels_Rd])\n",
    "sublabels_train_balanced = sublabels_train_balanced.sample(frac=1)\n",
    "\n",
    "sublabels_test_R = test[test[\"Label\"] == 0]\n",
    "sublabels_test = sublabels_test_R[[\"split\", \"Sublabel\"]].copy()\n",
    "sublabels_test.rename(columns={\"split\":\"Sentence\", \"Sublabel\":\"labels\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a072e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_train_balanced.to_csv(\"valence_most_active_train_balanced.csv\")\n",
    "binary_test.to_csv(\"valence_least_active_test.csv\")\n",
    "\n",
    "label_train_balanced.to_csv(\"label_most_active_train_balanced.csv\")\n",
    "label_test.to_csv(\"label_least_active_test.csv\")\n",
    "\n",
    "sublabels_train_balanced.to_csv(\"sublabel_most_active_train_balanced.csv\")\n",
    "sublabels_test.to_csv(\"sublabel_least_active_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
